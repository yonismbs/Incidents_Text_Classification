{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification d'incidents avec un réseau *feedforward* et des *embeddings* Spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On va entrainer un modèle de réseau de neurones de type feedforward multicouche (MLP) avec plongements de mots pour déterminer le type d’un incident à partir de sa description. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Création du jeu de données (*dataset*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/younismbs/anaconda3/envs/myEmv/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import spacy\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import FloatTensor, LongTensor\n",
    "from typing import List\n",
    "from poutyne.framework import Experiment\n",
    "from poutyne import set_seeds\n",
    "from torch.optim import SGD\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_json_fn = \"./data/incidents_train.json\"\n",
    "validation_json_fn = \"./data/incidents_test.json\"\n",
    "test_json_fn = \"./data/incidents_test.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Fonction permettant de charger les données\n",
    "def load_incident_dataset(filename):\n",
    "    with open(filename, 'r') as fp:\n",
    "        incident_list = json.load(fp)\n",
    "    return incident_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre d'incidents dans train: 2475\n",
      "Nombre d'incidents dans validation: 531\n",
      "Nombre d'incidents dans test: 531\n"
     ]
    }
   ],
   "source": [
    "train_list = load_incident_dataset(train_json_fn)\n",
    "validation_list = load_incident_dataset(validation_json_fn)\n",
    "test_list = load_incident_dataset(test_json_fn)\n",
    "\n",
    "print(\"Nombre d'incidents dans train:\", len(train_list))\n",
    "print(\"Nombre d'incidents dans validation:\", len(validation_list))\n",
    "print(\"Nombre d'incidents dans test:\", len(test_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#On divise nos listes en X(texte) et y(labels) pour chacun des sets\n",
    "\n",
    "X_train = [instance[\"text\"] for instance in train_list]\n",
    "y_train = [instance[\"label\"] for instance in train_list]\n",
    "\n",
    "X_val = [instance[\"text\"] for instance in validation_list]\n",
    "y_val = [instance[\"label\"] for instance in validation_list]\n",
    "\n",
    "X_test = [instance[\"text\"] for instance in test_list]\n",
    "y_test = [instance[\"label\"] for instance in test_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_classes = len(set(y_train))\n",
    "nb_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Gestion de plongements de mots (*embeddings*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-md==3.5.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_md-3.5.0/en_core_web_md-3.5.0-py3-none-any.whl (42.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.8/42.8 MB\u001b[0m \u001b[31m528.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:03\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: spacy<3.6.0,>=3.5.0 in /Users/younismbs/anaconda3/envs/myEmv/lib/python3.8/site-packages (from en-core-web-md==3.5.0) (3.5.3)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /Users/younismbs/anaconda3/envs/myEmv/lib/python3.8/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /Users/younismbs/anaconda3/envs/myEmv/lib/python3.8/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (1.0.4)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /Users/younismbs/anaconda3/envs/myEmv/lib/python3.8/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (1.0.7)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /Users/younismbs/anaconda3/envs/myEmv/lib/python3.8/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (2.0.6)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /Users/younismbs/anaconda3/envs/myEmv/lib/python3.8/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (3.0.6)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /Users/younismbs/anaconda3/envs/myEmv/lib/python3.8/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (8.1.10)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /Users/younismbs/anaconda3/envs/myEmv/lib/python3.8/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (0.9.1)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /Users/younismbs/anaconda3/envs/myEmv/lib/python3.8/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (2.4.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /Users/younismbs/anaconda3/envs/myEmv/lib/python3.8/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (2.0.7)\n",
      "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /Users/younismbs/anaconda3/envs/myEmv/lib/python3.8/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (0.4.1)\n",
      "Requirement already satisfied: pathy>=0.10.0 in /Users/younismbs/anaconda3/envs/myEmv/lib/python3.8/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (0.10.1)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /Users/younismbs/anaconda3/envs/myEmv/lib/python3.8/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (5.2.1)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /Users/younismbs/anaconda3/envs/myEmv/lib/python3.8/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (4.65.0)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /Users/younismbs/anaconda3/envs/myEmv/lib/python3.8/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (1.24.3)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /Users/younismbs/anaconda3/envs/myEmv/lib/python3.8/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (2.31.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /Users/younismbs/anaconda3/envs/myEmv/lib/python3.8/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (1.10.12)\n",
      "Requirement already satisfied: jinja2 in /Users/younismbs/anaconda3/envs/myEmv/lib/python3.8/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (3.1.2)\n",
      "Requirement already satisfied: setuptools in /Users/younismbs/anaconda3/envs/myEmv/lib/python3.8/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (68.0.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/younismbs/anaconda3/envs/myEmv/lib/python3.8/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (23.1)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /Users/younismbs/anaconda3/envs/myEmv/lib/python3.8/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (3.3.0)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /Users/younismbs/anaconda3/envs/myEmv/lib/python3.8/site-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (4.7.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/younismbs/anaconda3/envs/myEmv/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/younismbs/anaconda3/envs/myEmv/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/younismbs/anaconda3/envs/myEmv/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/younismbs/anaconda3/envs/myEmv/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (2023.7.22)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /Users/younismbs/anaconda3/envs/myEmv/lib/python3.8/site-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (0.7.9)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /Users/younismbs/anaconda3/envs/myEmv/lib/python3.8/site-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (0.0.4)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /Users/younismbs/anaconda3/envs/myEmv/lib/python3.8/site-packages (from typer<0.8.0,>=0.3.0->spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (8.1.7)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/younismbs/anaconda3/envs/myEmv/lib/python3.8/site-packages (from jinja2->spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (2.1.1)\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_md')\n"
     ]
    }
   ],
   "source": [
    "#On telecharge nos embeddings/tokenizer spacy\n",
    "spacy.cli.download(\"en_core_web_md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_md')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Création de modèle(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiLayerPerceptron(nn.Module):\n",
    "    def __init__(self, input_size, hidden_layer_size, output_size) :\n",
    "        super().__init__()\n",
    "        # Définition de la couche d'entrée à la couche cachée\n",
    "        self.intput_layer = nn.Linear(input_size, hidden_layer_size) #On a une couche cachée de taille hidden_layer_size\n",
    "        # Définition la couche cachée à la couche de sortie\n",
    "        self.output_layer = nn.Linear(hidden_layer_size, output_size)\n",
    "        \n",
    "    # Fonction forward permettant la propagation avant à travers la couche cachée avec une fonction d'activation ReLU entre les deux couches.\n",
    "    def forward(self, x):\n",
    "        x = self.intput_layer(x)\n",
    "        x = nn.functional.relu_(x)\n",
    "        x = self.output_layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Fonctions utilitaires"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans cette section on regroupe les differentes fonctions permettant de gerer l'agrégation des plongements de mots.\n",
    "\n",
    "Le processus de ces differentes fonctions sont presque identiques, la seul difference va resider dans la maniere dont on va \"fusionner\" nos plongements de mot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_embedding(sentence, nlp_model=nlp):\n",
    "    tokenised_sentence = nlp_model(sentence)  # Utilisation de notre tokenizer spaCy pour tokeniser la phrase en mots.\n",
    "    nb_column = len(tokenised_sentence) \n",
    "    nb_rows =  nlp_model.vocab.vectors_length # Récupération de la taille des embeddings de mots de spaCy (300).\n",
    "    sentence_embedding_matrix = np.zeros((nb_rows, nb_column)) \n",
    "    # Ce qu'on fait dans cette boucle, c'est qu'on itère sur chacun des mots de notre phrase et on récupère son embedding correspondant pour l'agréger à notre matrice en tant que colonne.\n",
    "    for index, token in enumerate(tokenised_sentence):\n",
    "        sentence_embedding_matrix[:, index] = token.vector\n",
    "    # À la fin, une fois qu'on a notre matrice complète, on fait la moyenne des colonnes (axis = 1) pour obtenir un vecteur qui sera donné en entrée à notre réseau.\n",
    "    return np.average(sentence_embedding_matrix, axis=1)\n",
    "\n",
    "def maxpool_embedding(sentence, nlp_model=nlp): \n",
    "    tokenised_sentence = nlp_model(sentence)\n",
    "    nb_column = len(tokenised_sentence)\n",
    "    nb_rows =  nlp_model.vocab.vectors_length \n",
    "    sentence_embedding_matrix = np.zeros((nb_rows, nb_column))                                    \n",
    "    for index, token in enumerate(tokenised_sentence):\n",
    "        sentence_embedding_matrix[:, index] = token.vector\n",
    "    # On fait un max pooling sur les colonnes pour récupérer la valeur maximale.\n",
    "    return np.max(sentence_embedding_matrix, axis=1)\n",
    "\n",
    "def minpool_embedding(sentence, nlp_model=nlp): \n",
    "    tokenised_sentence = nlp_model(sentence)\n",
    "    nb_column = len(tokenised_sentence)\n",
    "    nb_rows =  nlp_model.vocab.vectors_length \n",
    "    sentence_embedding_matrix = np.zeros((nb_rows, nb_column))                                    \n",
    "    for index, token in enumerate(tokenised_sentence):\n",
    "        sentence_embedding_matrix[:, index] = token.vector\n",
    "    # On fait un min pooling sur les colonnes pour récupérer la valeur minimale.\n",
    "    return np.min(sentence_embedding_matrix, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregations = {\n",
    "    \"average\" : average_embedding,\n",
    "    \"maxpool\" : maxpool_embedding,\n",
    "    \"minpool\" : minpool_embedding\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ici on definit une classe Dataset permettant de construire notre dataset en fonction des listes de phrases et des classes correspondantes, en utilisant la fonction d'agrégation définie précédemment.\n",
    "\n",
    "Notre dataset sera par la suite donnée a un dataloader qui se chargera de diviser notre dataset en batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpacyDataset(Dataset):\n",
    "    def __init__(self, dataset: List[str], target: np.array, sentence_aggregation_function):\n",
    "        self.dataset = dataset\n",
    "        self.doc_embeddings = [None for _ in range(len(dataset))]\n",
    "        self.sentence_aggregation_function = sentence_aggregation_function \n",
    "        self.target = target\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        if self.doc_embeddings[index] is None:\n",
    "            # Si l'embedding n'est pas encore défini pour l'index correspondant, alors on le construit en appelant notre fonction d'agrégation.\n",
    "            self.doc_embeddings[index] = self.sentence_aggregation_function(self.dataset[index]) \n",
    "        return FloatTensor(self.doc_embeddings[index]), LongTensor([int(self.target[index])]).squeeze(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Entraînement de modèle(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(nlp_model=nlp, aggregations=aggregations, hidden_size=100):\n",
    "    # Initialisation de dictionnaires pour stocker les modèles, les journaux (loggings) et les expériences pour chaque type d'agrégation.\n",
    "    models = {\"average\": None, \"maxpool\": None, \"minpool\": None}\n",
    "    loggings = {\"average\": None, \"maxpool\": None, \"minpool\": None}\n",
    "    experiments = {\"average\": None, \"maxpool\": None, \"minpool\": None}\n",
    "    test_dataloaders = {\"average\": None, \"maxpool\": None, \"minpool\": None}\n",
    "    \n",
    "    # Itération sur chaque type d'agrégation (moyenne, maxpool, minpool).\n",
    "    for key in aggregations.keys():\n",
    "        # Création des datasets pour l'entraînement, la validation et le test en utilisant l'agrégation courante.\n",
    "        train_dataset = SpacyDataset(X_train, y_train, aggregations[key])\n",
    "        valid_dataset = SpacyDataset(X_val, y_val, aggregations[key])\n",
    "        test_dataset = SpacyDataset(X_test, y_test, aggregations[key])\n",
    "\n",
    "        # Création des dataloaders pour l'entraînement, la validation et le test.\n",
    "        train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "        valid_dataloader = DataLoader(valid_dataset, batch_size=16, shuffle=True)\n",
    "        test_dataloaders[key] = DataLoader(test_dataset, batch_size=16, shuffle=True)\n",
    "\n",
    "        # Initialisation des graines pour assurer la reproductibilité.\n",
    "        set_seeds(42)\n",
    "\n",
    "        # Définition du nom du répertoire pour sauvegarder le modèle.\n",
    "        directory_name = 'model/{}_mlp'.format(aggregations[key].__name__)  \n",
    "\n",
    "        # Création du modèle de perceptron multicouche pour chaque agrégation.\n",
    "        models[key] = MultiLayerPerceptron(nlp_model.meta['vectors']['width'], hidden_size, nb_classes)\n",
    "\n",
    "        # Création d'une expérience pour chaque modèle.\n",
    "        experiments[key] = Experiment(directory_name, models[key], optimizer=\"Adam\", task=\"classification\")\n",
    "        \n",
    "        # Entraînement des modèles et stockage des résultats dans les journaux.\n",
    "        loggings[key] = experiments[key].train(train_dataloader, valid_dataloader, epochs=30, disable_tensorboard=True)\n",
    "    \n",
    "    # Retour des modèles, journaux, expériences et dataloaders de test.\n",
    "    return models, loggings, experiments, test_dataloaders\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le choix du nombre de couches cachées dépend du problème. Dans notre cas, on peut envisager qu'une taille de couche cachée entre 100 et 250 serait appropriée pour obtenir de bons résultats, en prenant en compte la taille de notre entrée (300) et de notre sortie (9). Si la couche cachée est excessivement grande, notre modèle pourrait ne pas être performant à cause du surapprentissage. Inversement, si la couche cachée est trop petite, notre réseau neuronal serait incapable de capturer suffisamment d'informations de nos embeddings de mots, conduisant à un sous-apprentissage. Dans mon cas, le nombre de couches cachées a été déterminé de manière itérative, en testant plusieurs valeurs dans l'intervalle estimé ci-dessus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35mEpoch: \u001b[36m 1/30 \u001b[35mTrain steps: \u001b[36m155 \u001b[35mVal steps: \u001b[36m34 \u001b[32m58.43s \u001b[35mloss:\u001b[94m 1.553585\u001b[35m acc:\u001b[94m 45.616162\u001b[35m fscore_macro:\u001b[94m 0.158856\u001b[35m val_loss:\u001b[94m 1.470433\u001b[35m val_acc:\u001b[94m 45.009416\u001b[35m val_fscore_macro:\u001b[94m 0.159505\u001b[0m\n",
      "Epoch 1: val_acc improved from -inf to 45.00942, saving file to model/average_embedding_mlp/checkpoint_epoch_1.ckpt\n",
      "\u001b[35mEpoch: \u001b[36m 2/30 \u001b[35mTrain steps: \u001b[36m155 \u001b[35mVal steps: \u001b[36m34 \u001b[32m0.10s \u001b[35mloss:\u001b[94m 1.297341\u001b[35m acc:\u001b[94m 54.585859\u001b[35m fscore_macro:\u001b[94m 0.252139\u001b[35m val_loss:\u001b[94m 1.280080\u001b[35m val_acc:\u001b[94m 52.730697\u001b[35m val_fscore_macro:\u001b[94m 0.265291\u001b[0m\n",
      "Epoch 2: val_acc improved from 45.00942 to 52.73070, saving file to model/average_embedding_mlp/checkpoint_epoch_2.ckpt\n",
      "\u001b[35mEpoch: \u001b[36m 3/30 \u001b[35mTrain steps: \u001b[36m155 \u001b[35mVal steps: \u001b[36m34 \u001b[32m0.09s \u001b[35mloss:\u001b[94m 1.161069\u001b[35m acc:\u001b[94m 59.232323\u001b[35m fscore_macro:\u001b[94m 0.327440\u001b[35m val_loss:\u001b[94m 1.144949\u001b[35m val_acc:\u001b[94m 59.322034\u001b[35m val_fscore_macro:\u001b[94m 0.363574\u001b[0m\n",
      "Epoch 3: val_acc improved from 52.73070 to 59.32203, saving file to model/average_embedding_mlp/checkpoint_epoch_3.ckpt\n",
      "\u001b[35mEpoch: \u001b[36m 4/30 \u001b[35mTrain steps: \u001b[36m155 \u001b[35mVal steps: \u001b[36m34 \u001b[32m0.11s \u001b[35mloss:\u001b[94m 1.083474\u001b[35m acc:\u001b[94m 61.737374\u001b[35m fscore_macro:\u001b[94m 0.363161\u001b[35m val_loss:\u001b[94m 1.080170\u001b[35m val_acc:\u001b[94m 60.640301\u001b[35m val_fscore_macro:\u001b[94m 0.360764\u001b[0m\n",
      "Epoch 4: val_acc improved from 59.32203 to 60.64030, saving file to model/average_embedding_mlp/checkpoint_epoch_4.ckpt\n",
      "\u001b[35mEpoch: \u001b[36m 5/30 \u001b[35mTrain steps: \u001b[36m155 \u001b[35mVal steps: \u001b[36m34 \u001b[32m0.10s \u001b[35mloss:\u001b[94m 1.000186\u001b[35m acc:\u001b[94m 64.161616\u001b[35m fscore_macro:\u001b[94m 0.396717\u001b[35m val_loss:\u001b[94m 1.048039\u001b[35m val_acc:\u001b[94m 66.854991\u001b[35m val_fscore_macro:\u001b[94m 0.443674\u001b[0m\n",
      "Epoch 5: val_acc improved from 60.64030 to 66.85499, saving file to model/average_embedding_mlp/checkpoint_epoch_5.ckpt\n",
      "\u001b[35mEpoch: \u001b[36m 6/30 \u001b[35mTrain steps: \u001b[36m155 \u001b[35mVal steps: \u001b[36m34 \u001b[32m0.09s \u001b[35mloss:\u001b[94m 0.969946\u001b[35m acc:\u001b[94m 65.212121\u001b[35m fscore_macro:\u001b[94m 0.417445\u001b[35m val_loss:\u001b[94m 1.051785\u001b[35m val_acc:\u001b[94m 66.290019\u001b[35m val_fscore_macro:\u001b[94m 0.435734\u001b[0m\n",
      "\u001b[35mEpoch: \u001b[36m 7/30 \u001b[35mTrain steps: \u001b[36m155 \u001b[35mVal steps: \u001b[36m34 \u001b[32m0.09s \u001b[35mloss:\u001b[94m 0.926910\u001b[35m acc:\u001b[94m 66.989899\u001b[35m fscore_macro:\u001b[94m 0.453240\u001b[35m val_loss:\u001b[94m 0.973011\u001b[35m val_acc:\u001b[94m 65.348399\u001b[35m val_fscore_macro:\u001b[94m 0.439225\u001b[0m\n",
      "\u001b[35mEpoch: \u001b[36m 8/30 \u001b[35mTrain steps: \u001b[36m155 \u001b[35mVal steps: \u001b[36m34 \u001b[32m0.09s \u001b[35mloss:\u001b[94m 0.907504\u001b[35m acc:\u001b[94m 68.000000\u001b[35m fscore_macro:\u001b[94m 0.477918\u001b[35m val_loss:\u001b[94m 0.992725\u001b[35m val_acc:\u001b[94m 65.725047\u001b[35m val_fscore_macro:\u001b[94m 0.430625\u001b[0m\n",
      "\u001b[35mEpoch: \u001b[36m 9/30 \u001b[35mTrain steps: \u001b[36m155 \u001b[35mVal steps: \u001b[36m34 \u001b[32m0.09s \u001b[35mloss:\u001b[94m 0.879145\u001b[35m acc:\u001b[94m 68.606061\u001b[35m fscore_macro:\u001b[94m 0.534065\u001b[35m val_loss:\u001b[94m 0.984013\u001b[35m val_acc:\u001b[94m 64.783428\u001b[35m val_fscore_macro:\u001b[94m 0.462813\u001b[0m\n",
      "\u001b[35mEpoch: \u001b[36m10/30 \u001b[35mTrain steps: \u001b[36m155 \u001b[35mVal steps: \u001b[36m34 \u001b[32m0.09s \u001b[35mloss:\u001b[94m 0.882241\u001b[35m acc:\u001b[94m 68.525253\u001b[35m fscore_macro:\u001b[94m 0.524978\u001b[35m val_loss:\u001b[94m 0.948144\u001b[35m val_acc:\u001b[94m 67.984934\u001b[35m val_fscore_macro:\u001b[94m 0.590744\u001b[0m\n",
      "Epoch 10: val_acc improved from 66.85499 to 67.98493, saving file to model/average_embedding_mlp/checkpoint_epoch_10.ckpt\n",
      "\u001b[35mEpoch: \u001b[36m11/30 \u001b[35mTrain steps: \u001b[36m155 \u001b[35mVal steps: \u001b[36m34 \u001b[32m0.09s \u001b[35mloss:\u001b[94m 0.837061\u001b[35m acc:\u001b[94m 70.101010\u001b[35m fscore_macro:\u001b[94m 0.552485\u001b[35m val_loss:\u001b[94m 0.978492\u001b[35m val_acc:\u001b[94m 66.666667\u001b[35m val_fscore_macro:\u001b[94m 0.533272\u001b[0m\n",
      "\u001b[35mEpoch: \u001b[36m12/30 \u001b[35mTrain steps: \u001b[36m155 \u001b[35mVal steps: \u001b[36m34 \u001b[32m0.09s \u001b[35mloss:\u001b[94m 0.853085\u001b[35m acc:\u001b[94m 69.252525\u001b[35m fscore_macro:\u001b[94m 0.562762\u001b[35m val_loss:\u001b[94m 0.956183\u001b[35m val_acc:\u001b[94m 68.549906\u001b[35m val_fscore_macro:\u001b[94m 0.575251\u001b[0m\n",
      "Epoch 12: val_acc improved from 67.98493 to 68.54991, saving file to model/average_embedding_mlp/checkpoint_epoch_12.ckpt\n",
      "\u001b[35mEpoch: \u001b[36m13/30 \u001b[35mTrain steps: \u001b[36m155 \u001b[35mVal steps: \u001b[36m34 \u001b[32m0.09s \u001b[35mloss:\u001b[94m 0.812521\u001b[35m acc:\u001b[94m 71.232323\u001b[35m fscore_macro:\u001b[94m 0.593845\u001b[35m val_loss:\u001b[94m 0.926885\u001b[35m val_acc:\u001b[94m 68.173258\u001b[35m val_fscore_macro:\u001b[94m 0.513779\u001b[0m\n",
      "\u001b[35mEpoch: \u001b[36m14/30 \u001b[35mTrain steps: \u001b[36m155 \u001b[35mVal steps: \u001b[36m34 \u001b[32m0.09s \u001b[35mloss:\u001b[94m 0.792152\u001b[35m acc:\u001b[94m 71.676768\u001b[35m fscore_macro:\u001b[94m 0.621788\u001b[35m val_loss:\u001b[94m 0.917855\u001b[35m val_acc:\u001b[94m 67.608286\u001b[35m val_fscore_macro:\u001b[94m 0.600924\u001b[0m\n",
      "\u001b[35mEpoch: \u001b[36m15/30 \u001b[35mTrain steps: \u001b[36m155 \u001b[35mVal steps: \u001b[36m34 \u001b[32m0.09s \u001b[35mloss:\u001b[94m 0.798213\u001b[35m acc:\u001b[94m 71.878788\u001b[35m fscore_macro:\u001b[94m 0.598038\u001b[35m val_loss:\u001b[94m 0.916369\u001b[35m val_acc:\u001b[94m 67.043315\u001b[35m val_fscore_macro:\u001b[94m 0.503891\u001b[0m\n",
      "\u001b[35mEpoch: \u001b[36m16/30 \u001b[35mTrain steps: \u001b[36m155 \u001b[35mVal steps: \u001b[36m34 \u001b[32m0.09s \u001b[35mloss:\u001b[94m 0.768685\u001b[35m acc:\u001b[94m 73.131313\u001b[35m fscore_macro:\u001b[94m 0.639232\u001b[35m val_loss:\u001b[94m 0.917114\u001b[35m val_acc:\u001b[94m 67.984934\u001b[35m val_fscore_macro:\u001b[94m 0.529449\u001b[0m\n",
      "\u001b[35mEpoch: \u001b[36m17/30 \u001b[35mTrain steps: \u001b[36m155 \u001b[35mVal steps: \u001b[36m34 \u001b[32m0.10s \u001b[35mloss:\u001b[94m 0.757298\u001b[35m acc:\u001b[94m 72.686869\u001b[35m fscore_macro:\u001b[94m 0.642116\u001b[35m val_loss:\u001b[94m 0.913042\u001b[35m val_acc:\u001b[94m 67.231638\u001b[35m val_fscore_macro:\u001b[94m 0.592041\u001b[0m\n",
      "\u001b[35mEpoch: \u001b[36m18/30 \u001b[35mTrain steps: \u001b[36m155 \u001b[35mVal steps: \u001b[36m34 \u001b[32m0.10s \u001b[35mloss:\u001b[94m 0.749869\u001b[35m acc:\u001b[94m 72.929293\u001b[35m fscore_macro:\u001b[94m 0.649641\u001b[35m val_loss:\u001b[94m 0.931050\u001b[35m val_acc:\u001b[94m 66.478343\u001b[35m val_fscore_macro:\u001b[94m 0.569730\u001b[0m\n",
      "\u001b[35mEpoch: \u001b[36m19/30 \u001b[35mTrain steps: \u001b[36m155 \u001b[35mVal steps: \u001b[36m34 \u001b[32m0.09s \u001b[35mloss:\u001b[94m 0.729331\u001b[35m acc:\u001b[94m 74.505051\u001b[35m fscore_macro:\u001b[94m 0.671750\u001b[35m val_loss:\u001b[94m 0.914055\u001b[35m val_acc:\u001b[94m 69.114878\u001b[35m val_fscore_macro:\u001b[94m 0.585599\u001b[0m\n",
      "Epoch 19: val_acc improved from 68.54991 to 69.11488, saving file to model/average_embedding_mlp/checkpoint_epoch_19.ckpt\n",
      "\u001b[35mEpoch: \u001b[36m20/30 \u001b[35mTrain steps: \u001b[36m155 \u001b[35mVal steps: \u001b[36m34 \u001b[32m0.09s \u001b[35mloss:\u001b[94m 0.722461\u001b[35m acc:\u001b[94m 74.464646\u001b[35m fscore_macro:\u001b[94m 0.679354\u001b[35m val_loss:\u001b[94m 0.941634\u001b[35m val_acc:\u001b[94m 69.868173\u001b[35m val_fscore_macro:\u001b[94m 0.643928\u001b[0m\n",
      "Epoch 20: val_acc improved from 69.11488 to 69.86817, saving file to model/average_embedding_mlp/checkpoint_epoch_20.ckpt\n",
      "\u001b[35mEpoch: \u001b[36m21/30 \u001b[35mTrain steps: \u001b[36m155 \u001b[35mVal steps: \u001b[36m34 \u001b[32m0.09s \u001b[35mloss:\u001b[94m 0.713453\u001b[35m acc:\u001b[94m 74.464646\u001b[35m fscore_macro:\u001b[94m 0.669248\u001b[35m val_loss:\u001b[94m 0.962668\u001b[35m val_acc:\u001b[94m 66.666667\u001b[35m val_fscore_macro:\u001b[94m 0.546758\u001b[0m\n",
      "\u001b[35mEpoch: \u001b[36m22/30 \u001b[35mTrain steps: \u001b[36m155 \u001b[35mVal steps: \u001b[36m34 \u001b[32m0.10s \u001b[35mloss:\u001b[94m 0.705635\u001b[35m acc:\u001b[94m 75.151515\u001b[35m fscore_macro:\u001b[94m 0.702491\u001b[35m val_loss:\u001b[94m 0.966780\u001b[35m val_acc:\u001b[94m 66.478343\u001b[35m val_fscore_macro:\u001b[94m 0.531308\u001b[0m\n",
      "\u001b[35mEpoch: \u001b[36m23/30 \u001b[35mTrain steps: \u001b[36m155 \u001b[35mVal steps: \u001b[36m34 \u001b[32m0.09s \u001b[35mloss:\u001b[94m 0.698995\u001b[35m acc:\u001b[94m 74.828283\u001b[35m fscore_macro:\u001b[94m 0.677726\u001b[35m val_loss:\u001b[94m 0.917987\u001b[35m val_acc:\u001b[94m 68.173258\u001b[35m val_fscore_macro:\u001b[94m 0.554158\u001b[0m\n",
      "\u001b[35mEpoch: \u001b[36m24/30 \u001b[35mTrain steps: \u001b[36m155 \u001b[35mVal steps: \u001b[36m34 \u001b[32m0.09s \u001b[35mloss:\u001b[94m 0.707008\u001b[35m acc:\u001b[94m 74.909091\u001b[35m fscore_macro:\u001b[94m 0.698707\u001b[35m val_loss:\u001b[94m 0.913530\u001b[35m val_acc:\u001b[94m 69.491525\u001b[35m val_fscore_macro:\u001b[94m 0.638450\u001b[0m\n",
      "\u001b[35mEpoch: \u001b[36m25/30 \u001b[35mTrain steps: \u001b[36m155 \u001b[35mVal steps: \u001b[36m34 \u001b[32m0.09s \u001b[35mloss:\u001b[94m 0.691940\u001b[35m acc:\u001b[94m 75.191919\u001b[35m fscore_macro:\u001b[94m 0.722190\u001b[35m val_loss:\u001b[94m 0.988071\u001b[35m val_acc:\u001b[94m 66.290019\u001b[35m val_fscore_macro:\u001b[94m 0.605295\u001b[0m\n",
      "\u001b[35mEpoch: \u001b[36m26/30 \u001b[35mTrain steps: \u001b[36m155 \u001b[35mVal steps: \u001b[36m34 \u001b[32m0.09s \u001b[35mloss:\u001b[94m 0.676134\u001b[35m acc:\u001b[94m 76.121212\u001b[35m fscore_macro:\u001b[94m 0.717418\u001b[35m val_loss:\u001b[94m 0.891965\u001b[35m val_acc:\u001b[94m 69.303202\u001b[35m val_fscore_macro:\u001b[94m 0.612583\u001b[0m\n",
      "\u001b[35mEpoch: \u001b[36m27/30 \u001b[35mTrain steps: \u001b[36m155 \u001b[35mVal steps: \u001b[36m34 \u001b[32m0.09s \u001b[35mloss:\u001b[94m 0.648886\u001b[35m acc:\u001b[94m 75.919192\u001b[35m fscore_macro:\u001b[94m 0.714073\u001b[35m val_loss:\u001b[94m 0.958967\u001b[35m val_acc:\u001b[94m 67.231638\u001b[35m val_fscore_macro:\u001b[94m 0.615470\u001b[0m\n",
      "\u001b[35mEpoch: \u001b[36m28/30 \u001b[35mTrain steps: \u001b[36m155 \u001b[35mVal steps: \u001b[36m34 \u001b[32m0.09s \u001b[35mloss:\u001b[94m 0.655749\u001b[35m acc:\u001b[94m 76.969697\u001b[35m fscore_macro:\u001b[94m 0.734187\u001b[35m val_loss:\u001b[94m 0.962773\u001b[35m val_acc:\u001b[94m 67.419962\u001b[35m val_fscore_macro:\u001b[94m 0.660334\u001b[0m\n",
      "\u001b[35mEpoch: \u001b[36m29/30 \u001b[35mTrain steps: \u001b[36m155 \u001b[35mVal steps: \u001b[36m34 \u001b[32m0.09s \u001b[35mloss:\u001b[94m 0.651480\u001b[35m acc:\u001b[94m 76.202020\u001b[35m fscore_macro:\u001b[94m 0.729445\u001b[35m val_loss:\u001b[94m 0.965749\u001b[35m val_acc:\u001b[94m 68.738230\u001b[35m val_fscore_macro:\u001b[94m 0.624307\u001b[0m\n",
      "\u001b[35mEpoch: \u001b[36m30/30 \u001b[35mTrain steps: \u001b[36m155 \u001b[35mVal steps: \u001b[36m34 \u001b[32m0.10s \u001b[35mloss:\u001b[94m 0.632674\u001b[35m acc:\u001b[94m 77.858586\u001b[35m fscore_macro:\u001b[94m 0.758985\u001b[35m val_loss:\u001b[94m 0.946139\u001b[35m val_acc:\u001b[94m 70.809793\u001b[35m val_fscore_macro:\u001b[94m 0.675723\u001b[0m\n",
      "Epoch 30: val_acc improved from 69.86817 to 70.80979, saving file to model/average_embedding_mlp/checkpoint_epoch_30.ckpt\n",
      "Restoring data from model/average_embedding_mlp/checkpoint_epoch_30.ckpt\n",
      "\u001b[35mEpoch: \u001b[36m 1/30 \u001b[35mTrain steps: \u001b[36m155 \u001b[35mVal steps: \u001b[36m34 \u001b[32m59.60s \u001b[35mloss:\u001b[94m 1.955499\u001b[35m acc:\u001b[94m 35.636364\u001b[35m fscore_macro:\u001b[94m 0.095913\u001b[35m val_loss:\u001b[94m 1.828830\u001b[35m val_acc:\u001b[94m 35.969868\u001b[35m val_fscore_macro:\u001b[94m 0.058787\u001b[0m\n",
      "Epoch 1: val_acc improved from -inf to 35.96987, saving file to model/maxpool_embedding_mlp/checkpoint_epoch_1.ckpt\n",
      "\u001b[35mEpoch: \u001b[36m 2/30 \u001b[35mTrain steps: \u001b[36m155 \u001b[35mVal steps: \u001b[36m34 \u001b[32m0.10s \u001b[35mloss:\u001b[94m 1.695566\u001b[35m acc:\u001b[94m 39.353535\u001b[35m fscore_macro:\u001b[94m 0.104877\u001b[35m val_loss:\u001b[94m 1.753954\u001b[35m val_acc:\u001b[94m 37.476460\u001b[35m val_fscore_macro:\u001b[94m 0.084456\u001b[0m\n",
      "Epoch 2: val_acc improved from 35.96987 to 37.47646, saving file to model/maxpool_embedding_mlp/checkpoint_epoch_2.ckpt\n",
      "\u001b[35mEpoch: \u001b[36m 3/30 \u001b[35mTrain steps: \u001b[36m155 \u001b[35mVal steps: \u001b[36m34 \u001b[32m0.09s \u001b[35mloss:\u001b[94m 1.693376\u001b[35m acc:\u001b[94m 39.151515\u001b[35m fscore_macro:\u001b[94m 0.098604\u001b[35m val_loss:\u001b[94m 1.725740\u001b[35m val_acc:\u001b[94m 37.099812\u001b[35m val_fscore_macro:\u001b[94m 0.080772\u001b[0m\n",
      "\u001b[35mEpoch: \u001b[36m 4/30 \u001b[35mTrain steps: \u001b[36m155 \u001b[35mVal steps: \u001b[36m34 \u001b[32m0.09s \u001b[35mloss:\u001b[94m 1.649789\u001b[35m acc:\u001b[94m 40.808081\u001b[35m fscore_macro:\u001b[94m 0.122017\u001b[35m val_loss:\u001b[94m 1.676283\u001b[35m val_acc:\u001b[94m 38.229755\u001b[35m val_fscore_macro:\u001b[94m 0.106081\u001b[0m\n",
      "Epoch 4: val_acc improved from 37.47646 to 38.22976, saving file to model/maxpool_embedding_mlp/checkpoint_epoch_4.ckpt\n",
      "\u001b[35mEpoch: \u001b[36m 5/30 \u001b[35mTrain steps: \u001b[36m155 \u001b[35mVal steps: \u001b[36m34 \u001b[32m0.09s \u001b[35mloss:\u001b[94m 1.608359\u001b[35m acc:\u001b[94m 42.505051\u001b[35m fscore_macro:\u001b[94m 0.134548\u001b[35m val_loss:\u001b[94m 1.650312\u001b[35m val_acc:\u001b[94m 40.866290\u001b[35m val_fscore_macro:\u001b[94m 0.150058\u001b[0m\n",
      "Epoch 5: val_acc improved from 38.22976 to 40.86629, saving file to model/maxpool_embedding_mlp/checkpoint_epoch_5.ckpt\n",
      "\u001b[35mEpoch: \u001b[36m 6/30 \u001b[35mTrain steps: \u001b[36m155 \u001b[35mVal steps: \u001b[36m34 \u001b[32m0.09s \u001b[35mloss:\u001b[94m 1.601295\u001b[35m acc:\u001b[94m 41.777778\u001b[35m fscore_macro:\u001b[94m 0.140505\u001b[35m val_loss:\u001b[94m 1.708448\u001b[35m val_acc:\u001b[94m 36.158192\u001b[35m val_fscore_macro:\u001b[94m 0.139586\u001b[0m\n",
      "\u001b[35mEpoch: \u001b[36m 7/30 \u001b[35mTrain steps: \u001b[36m155 \u001b[35mVal steps: \u001b[36m34 \u001b[32m0.09s \u001b[35mloss:\u001b[94m 1.580526\u001b[35m acc:\u001b[94m 43.515152\u001b[35m fscore_macro:\u001b[94m 0.148270\u001b[35m val_loss:\u001b[94m 1.605355\u001b[35m val_acc:\u001b[94m 41.619586\u001b[35m val_fscore_macro:\u001b[94m 0.150404\u001b[0m\n",
      "Epoch 7: val_acc improved from 40.86629 to 41.61959, saving file to model/maxpool_embedding_mlp/checkpoint_epoch_7.ckpt\n",
      "\u001b[35mEpoch: \u001b[36m 8/30 \u001b[35mTrain steps: \u001b[36m155 \u001b[35mVal steps: \u001b[36m34 \u001b[32m0.09s \u001b[35mloss:\u001b[94m 1.574908\u001b[35m acc:\u001b[94m 43.474747\u001b[35m fscore_macro:\u001b[94m 0.144918\u001b[35m val_loss:\u001b[94m 1.662966\u001b[35m val_acc:\u001b[94m 40.301318\u001b[35m val_fscore_macro:\u001b[94m 0.125385\u001b[0m\n",
      "\u001b[35mEpoch: \u001b[36m 9/30 \u001b[35mTrain steps: \u001b[36m155 \u001b[35mVal steps: \u001b[36m34 \u001b[32m0.09s \u001b[35mloss:\u001b[94m 1.561515\u001b[35m acc:\u001b[94m 42.666667\u001b[35m fscore_macro:\u001b[94m 0.142433\u001b[35m val_loss:\u001b[94m 1.607545\u001b[35m val_acc:\u001b[94m 40.677966\u001b[35m val_fscore_macro:\u001b[94m 0.153472\u001b[0m\n",
      "\u001b[35mEpoch: \u001b[36m10/30 \u001b[35mTrain steps: \u001b[36m155 \u001b[35mVal steps: \u001b[36m34 \u001b[32m0.09s \u001b[35mloss:\u001b[94m 1.550124\u001b[35m acc:\u001b[94m 43.313131\u001b[35m fscore_macro:\u001b[94m 0.148347\u001b[35m val_loss:\u001b[94m 1.626808\u001b[35m val_acc:\u001b[94m 41.996234\u001b[35m val_fscore_macro:\u001b[94m 0.161517\u001b[0m\n",
      "Epoch 10: val_acc improved from 41.61959 to 41.99623, saving file to model/maxpool_embedding_mlp/checkpoint_epoch_10.ckpt\n",
      "\u001b[35mEpoch: \u001b[36m11/30 \u001b[35mTrain steps: \u001b[36m155 \u001b[35mVal steps: \u001b[36m34 \u001b[32m0.09s \u001b[35mloss:\u001b[94m 1.541230\u001b[35m acc:\u001b[94m 44.646465\u001b[35m fscore_macro:\u001b[94m 0.155648\u001b[35m val_loss:\u001b[94m 1.656042\u001b[35m val_acc:\u001b[94m 42.372881\u001b[35m val_fscore_macro:\u001b[94m 0.145861\u001b[0m\n",
      "Epoch 11: val_acc improved from 41.99623 to 42.37288, saving file to model/maxpool_embedding_mlp/checkpoint_epoch_11.ckpt\n",
      "\u001b[35mEpoch: \u001b[36m12/30 \u001b[35mTrain steps: \u001b[36m155 \u001b[35mVal steps: \u001b[36m34 \u001b[32m0.09s \u001b[35mloss:\u001b[94m 1.547340\u001b[35m acc:\u001b[94m 44.161616\u001b[35m fscore_macro:\u001b[94m 0.155099\u001b[35m val_loss:\u001b[94m 1.590902\u001b[35m val_acc:\u001b[94m 41.431262\u001b[35m val_fscore_macro:\u001b[94m 0.151112\u001b[0m\n",
      "\u001b[35mEpoch: \u001b[36m13/30 \u001b[35mTrain steps: \u001b[36m155 \u001b[35mVal steps: \u001b[36m34 \u001b[32m0.09s \u001b[35mloss:\u001b[94m 1.533389\u001b[35m acc:\u001b[94m 44.686869\u001b[35m fscore_macro:\u001b[94m 0.156366\u001b[35m val_loss:\u001b[94m 1.573383\u001b[35m val_acc:\u001b[94m 41.431262\u001b[35m val_fscore_macro:\u001b[94m 0.153505\u001b[0m\n",
      "\u001b[35mEpoch: \u001b[36m14/30 \u001b[35mTrain steps: \u001b[36m155 \u001b[35mVal steps: \u001b[36m34 \u001b[32m0.10s \u001b[35mloss:\u001b[94m 1.504812\u001b[35m acc:\u001b[94m 45.494949\u001b[35m fscore_macro:\u001b[94m 0.169604\u001b[35m val_loss:\u001b[94m 1.569502\u001b[35m val_acc:\u001b[94m 42.184557\u001b[35m val_fscore_macro:\u001b[94m 0.147313\u001b[0m\n",
      "\u001b[35mEpoch: \u001b[36m15/30 \u001b[35mTrain steps: \u001b[36m155 \u001b[35mVal steps: \u001b[36m34 \u001b[32m0.09s \u001b[35mloss:\u001b[94m 1.512673\u001b[35m acc:\u001b[94m 46.424242\u001b[35m fscore_macro:\u001b[94m 0.165431\u001b[35m val_loss:\u001b[94m 1.627479\u001b[35m val_acc:\u001b[94m 41.054614\u001b[35m val_fscore_macro:\u001b[94m 0.129558\u001b[0m\n",
      "\u001b[35mEpoch: \u001b[36m16/30 \u001b[35mTrain steps: \u001b[36m155 \u001b[35mVal steps: \u001b[36m34 \u001b[32m0.09s \u001b[35mloss:\u001b[94m 1.506709\u001b[35m acc:\u001b[94m 46.222222\u001b[35m fscore_macro:\u001b[94m 0.167511\u001b[35m val_loss:\u001b[94m 1.646767\u001b[35m val_acc:\u001b[94m 36.534840\u001b[35m val_fscore_macro:\u001b[94m 0.150120\u001b[0m\n",
      "\u001b[35mEpoch: \u001b[36m17/30 \u001b[35mTrain steps: \u001b[36m155 \u001b[35mVal steps: \u001b[36m34 \u001b[32m0.09s \u001b[35mloss:\u001b[94m 1.506385\u001b[35m acc:\u001b[94m 45.171717\u001b[35m fscore_macro:\u001b[94m 0.163853\u001b[35m val_loss:\u001b[94m 1.557852\u001b[35m val_acc:\u001b[94m 41.996234\u001b[35m val_fscore_macro:\u001b[94m 0.142235\u001b[0m\n",
      "\u001b[35mEpoch: \u001b[36m18/30 \u001b[35mTrain steps: \u001b[36m155 \u001b[35mVal steps: \u001b[36m34 \u001b[32m0.09s \u001b[35mloss:\u001b[94m 1.493626\u001b[35m acc:\u001b[94m 45.616162\u001b[35m fscore_macro:\u001b[94m 0.182745\u001b[35m val_loss:\u001b[94m 1.643151\u001b[35m val_acc:\u001b[94m 41.054614\u001b[35m val_fscore_macro:\u001b[94m 0.130884\u001b[0m\n",
      "\u001b[35mEpoch: \u001b[36m19/30 \u001b[35mTrain steps: \u001b[36m155 \u001b[35mVal steps: \u001b[36m34 \u001b[32m0.09s \u001b[35mloss:\u001b[94m 1.492945\u001b[35m acc:\u001b[94m 46.626263\u001b[35m fscore_macro:\u001b[94m 0.166536\u001b[35m val_loss:\u001b[94m 1.576502\u001b[35m val_acc:\u001b[94m 41.431262\u001b[35m val_fscore_macro:\u001b[94m 0.135117\u001b[0m\n",
      "\u001b[35mEpoch: \u001b[36m20/30 \u001b[35mTrain steps: \u001b[36m155 \u001b[35mVal steps: \u001b[36m34 \u001b[32m0.09s \u001b[35mloss:\u001b[94m 1.479245\u001b[35m acc:\u001b[94m 45.777778\u001b[35m fscore_macro:\u001b[94m 0.211897\u001b[35m val_loss:\u001b[94m 1.561522\u001b[35m val_acc:\u001b[94m 43.314501\u001b[35m val_fscore_macro:\u001b[94m 0.173124\u001b[0m\n",
      "Epoch 20: val_acc improved from 42.37288 to 43.31450, saving file to model/maxpool_embedding_mlp/checkpoint_epoch_20.ckpt\n",
      "\u001b[35mEpoch: \u001b[36m21/30 \u001b[35mTrain steps: \u001b[36m155 \u001b[35mVal steps: \u001b[36m34 \u001b[32m0.09s \u001b[35mloss:\u001b[94m 1.467918\u001b[35m acc:\u001b[94m 47.070707\u001b[35m fscore_macro:\u001b[94m 0.207560\u001b[35m val_loss:\u001b[94m 1.536669\u001b[35m val_acc:\u001b[94m 42.749529\u001b[35m val_fscore_macro:\u001b[94m 0.159901\u001b[0m\n",
      "\u001b[35mEpoch: \u001b[36m22/30 \u001b[35mTrain steps: \u001b[36m155 \u001b[35mVal steps: \u001b[36m34 \u001b[32m0.09s \u001b[35mloss:\u001b[94m 1.453920\u001b[35m acc:\u001b[94m 46.383838\u001b[35m fscore_macro:\u001b[94m 0.201958\u001b[35m val_loss:\u001b[94m 1.571391\u001b[35m val_acc:\u001b[94m 40.301318\u001b[35m val_fscore_macro:\u001b[94m 0.262594\u001b[0m\n",
      "\u001b[35mEpoch: \u001b[36m23/30 \u001b[35mTrain steps: \u001b[36m155 \u001b[35mVal steps: \u001b[36m34 \u001b[32m0.09s \u001b[35mloss:\u001b[94m 1.453401\u001b[35m acc:\u001b[94m 47.474747\u001b[35m fscore_macro:\u001b[94m 0.224566\u001b[35m val_loss:\u001b[94m 1.600346\u001b[35m val_acc:\u001b[94m 42.937853\u001b[35m val_fscore_macro:\u001b[94m 0.225847\u001b[0m\n",
      "\u001b[35mEpoch: \u001b[36m24/30 \u001b[35mTrain steps: \u001b[36m155 \u001b[35mVal steps: \u001b[36m34 \u001b[32m0.09s \u001b[35mloss:\u001b[94m 1.501365\u001b[35m acc:\u001b[94m 44.646465\u001b[35m fscore_macro:\u001b[94m 0.210120\u001b[35m val_loss:\u001b[94m 1.557674\u001b[35m val_acc:\u001b[94m 42.937853\u001b[35m val_fscore_macro:\u001b[94m 0.150415\u001b[0m\n",
      "\u001b[35mEpoch: \u001b[36m25/30 \u001b[35mTrain steps: \u001b[36m155 \u001b[35mVal steps: \u001b[36m34 \u001b[32m0.09s \u001b[35mloss:\u001b[94m 1.457453\u001b[35m acc:\u001b[94m 46.747475\u001b[35m fscore_macro:\u001b[94m 0.241467\u001b[35m val_loss:\u001b[94m 1.538234\u001b[35m val_acc:\u001b[94m 44.444444\u001b[35m val_fscore_macro:\u001b[94m 0.221212\u001b[0m\n",
      "Epoch 25: val_acc improved from 43.31450 to 44.44444, saving file to model/maxpool_embedding_mlp/checkpoint_epoch_25.ckpt\n",
      "\u001b[35mEpoch: \u001b[36m26/30 \u001b[35mTrain steps: \u001b[36m155 \u001b[35mVal steps: \u001b[36m34 \u001b[32m0.09s \u001b[35mloss:\u001b[94m 1.461947\u001b[35m acc:\u001b[94m 46.747475\u001b[35m fscore_macro:\u001b[94m 0.217902\u001b[35m val_loss:\u001b[94m 1.592626\u001b[35m val_acc:\u001b[94m 41.431262\u001b[35m val_fscore_macro:\u001b[94m 0.204224\u001b[0m\n",
      "\u001b[35mEpoch: \u001b[36m27/30 \u001b[35mTrain steps: \u001b[36m155 \u001b[35mVal steps: \u001b[36m34 \u001b[32m0.09s \u001b[35mloss:\u001b[94m 1.434576\u001b[35m acc:\u001b[94m 47.838384\u001b[35m fscore_macro:\u001b[94m 0.257554\u001b[35m val_loss:\u001b[94m 1.538600\u001b[35m val_acc:\u001b[94m 43.126177\u001b[35m val_fscore_macro:\u001b[94m 0.193614\u001b[0m\n",
      "\u001b[35mEpoch: \u001b[36m28/30 \u001b[35mTrain steps: \u001b[36m155 \u001b[35mVal steps: \u001b[36m34 \u001b[32m0.09s \u001b[35mloss:\u001b[94m 1.454358\u001b[35m acc:\u001b[94m 46.666667\u001b[35m fscore_macro:\u001b[94m 0.225947\u001b[35m val_loss:\u001b[94m 1.576388\u001b[35m val_acc:\u001b[94m 41.996234\u001b[35m val_fscore_macro:\u001b[94m 0.148195\u001b[0m\n",
      "\u001b[35mEpoch: \u001b[36m29/30 \u001b[35mTrain steps: \u001b[36m155 \u001b[35mVal steps: \u001b[36m34 \u001b[32m0.10s \u001b[35mloss:\u001b[94m 1.431207\u001b[35m acc:\u001b[94m 47.757576\u001b[35m fscore_macro:\u001b[94m 0.262220\u001b[35m val_loss:\u001b[94m 1.576126\u001b[35m val_acc:\u001b[94m 43.691149\u001b[35m val_fscore_macro:\u001b[94m 0.172633\u001b[0m\n",
      "\u001b[35mEpoch: \u001b[36m30/30 \u001b[35mTrain steps: \u001b[36m155 \u001b[35mVal steps: \u001b[36m34 \u001b[32m0.09s \u001b[35mloss:\u001b[94m 1.431088\u001b[35m acc:\u001b[94m 48.929293\u001b[35m fscore_macro:\u001b[94m 0.278957\u001b[35m val_loss:\u001b[94m 1.521630\u001b[35m val_acc:\u001b[94m 45.197740\u001b[35m val_fscore_macro:\u001b[94m 0.182609\u001b[0m\n",
      "Epoch 30: val_acc improved from 44.44444 to 45.19774, saving file to model/maxpool_embedding_mlp/checkpoint_epoch_30.ckpt\n",
      "Restoring data from model/maxpool_embedding_mlp/checkpoint_epoch_30.ckpt\n",
      "\u001b[35mEpoch: \u001b[36m 1/30 \u001b[35mTrain steps: \u001b[36m155 \u001b[35mVal steps: \u001b[36m34 \u001b[32m58.22s \u001b[35mloss:\u001b[94m 1.942836\u001b[35m acc:\u001b[94m 35.757576\u001b[35m fscore_macro:\u001b[94m 0.106952\u001b[35m val_loss:\u001b[94m 1.747652\u001b[35m val_acc:\u001b[94m 36.723164\u001b[35m val_fscore_macro:\u001b[94m 0.077889\u001b[0m\n",
      "Epoch 1: val_acc improved from -inf to 36.72316, saving file to model/minpool_embedding_mlp/checkpoint_epoch_1.ckpt\n",
      "\u001b[35mEpoch: \u001b[36m 2/30 \u001b[35mTrain steps: \u001b[36m155 \u001b[35mVal steps: \u001b[36m34 \u001b[32m0.10s \u001b[35mloss:\u001b[94m 1.672375\u001b[35m acc:\u001b[94m 39.070707\u001b[35m fscore_macro:\u001b[94m 0.120495\u001b[35m val_loss:\u001b[94m 1.667814\u001b[35m val_acc:\u001b[94m 42.372881\u001b[35m val_fscore_macro:\u001b[94m 0.138963\u001b[0m\n",
      "Epoch 2: val_acc improved from 36.72316 to 42.37288, saving file to model/minpool_embedding_mlp/checkpoint_epoch_2.ckpt\n",
      "\u001b[35mEpoch: \u001b[36m 3/30 \u001b[35mTrain steps: \u001b[36m155 \u001b[35mVal steps: \u001b[36m34 \u001b[32m0.10s \u001b[35mloss:\u001b[94m 1.630524\u001b[35m acc:\u001b[94m 41.333333\u001b[35m fscore_macro:\u001b[94m 0.142262\u001b[35m val_loss:\u001b[94m 1.656285\u001b[35m val_acc:\u001b[94m 40.677966\u001b[35m val_fscore_macro:\u001b[94m 0.151185\u001b[0m\n",
      "\u001b[35mEpoch: \u001b[36m 4/30 \u001b[35mTrain steps: \u001b[36m155 \u001b[35mVal steps: \u001b[36m34 \u001b[32m0.10s \u001b[35mloss:\u001b[94m 1.599753\u001b[35m acc:\u001b[94m 42.787879\u001b[35m fscore_macro:\u001b[94m 0.145461\u001b[35m val_loss:\u001b[94m 1.603080\u001b[35m val_acc:\u001b[94m 43.879473\u001b[35m val_fscore_macro:\u001b[94m 0.160945\u001b[0m\n",
      "Epoch 4: val_acc improved from 42.37288 to 43.87947, saving file to model/minpool_embedding_mlp/checkpoint_epoch_4.ckpt\n",
      "\u001b[35mEpoch: \u001b[36m 5/30 \u001b[35mTrain steps: \u001b[36m155 \u001b[35mVal steps: \u001b[36m34 \u001b[32m0.10s \u001b[35mloss:\u001b[94m 1.566752\u001b[35m acc:\u001b[94m 43.919192\u001b[35m fscore_macro:\u001b[94m 0.151933\u001b[35m val_loss:\u001b[94m 1.604314\u001b[35m val_acc:\u001b[94m 43.126177\u001b[35m val_fscore_macro:\u001b[94m 0.146300\u001b[0m\n",
      "\u001b[35mEpoch: \u001b[36m 6/30 \u001b[35mTrain steps: \u001b[36m155 \u001b[35mVal steps: \u001b[36m34 \u001b[32m0.09s \u001b[35mloss:\u001b[94m 1.546488\u001b[35m acc:\u001b[94m 45.414141\u001b[35m fscore_macro:\u001b[94m 0.162792\u001b[35m val_loss:\u001b[94m 1.590441\u001b[35m val_acc:\u001b[94m 41.807910\u001b[35m val_fscore_macro:\u001b[94m 0.143438\u001b[0m\n",
      "\u001b[35mEpoch: \u001b[36m 7/30 \u001b[35mTrain steps: \u001b[36m155 \u001b[35mVal steps: \u001b[36m34 \u001b[32m0.09s \u001b[35mloss:\u001b[94m 1.536176\u001b[35m acc:\u001b[94m 44.969697\u001b[35m fscore_macro:\u001b[94m 0.161722\u001b[35m val_loss:\u001b[94m 1.551423\u001b[35m val_acc:\u001b[94m 44.821092\u001b[35m val_fscore_macro:\u001b[94m 0.159191\u001b[0m\n",
      "Epoch 7: val_acc improved from 43.87947 to 44.82109, saving file to model/minpool_embedding_mlp/checkpoint_epoch_7.ckpt\n",
      "\u001b[35mEpoch: \u001b[36m 8/30 \u001b[35mTrain steps: \u001b[36m155 \u001b[35mVal steps: \u001b[36m34 \u001b[32m0.10s \u001b[35mloss:\u001b[94m 1.513795\u001b[35m acc:\u001b[94m 45.737374\u001b[35m fscore_macro:\u001b[94m 0.165424\u001b[35m val_loss:\u001b[94m 1.625886\u001b[35m val_acc:\u001b[94m 43.314501\u001b[35m val_fscore_macro:\u001b[94m 0.155492\u001b[0m\n",
      "\u001b[35mEpoch: \u001b[36m 9/30 \u001b[35mTrain steps: \u001b[36m155 \u001b[35mVal steps: \u001b[36m34 \u001b[32m0.10s \u001b[35mloss:\u001b[94m 1.500320\u001b[35m acc:\u001b[94m 46.585859\u001b[35m fscore_macro:\u001b[94m 0.168866\u001b[35m val_loss:\u001b[94m 1.534179\u001b[35m val_acc:\u001b[94m 46.704331\u001b[35m val_fscore_macro:\u001b[94m 0.197063\u001b[0m\n",
      "Epoch 9: val_acc improved from 44.82109 to 46.70433, saving file to model/minpool_embedding_mlp/checkpoint_epoch_9.ckpt\n",
      "\u001b[35mEpoch: \u001b[36m10/30 \u001b[35mTrain steps: \u001b[36m155 \u001b[35mVal steps: \u001b[36m34 \u001b[32m0.10s \u001b[35mloss:\u001b[94m 1.479135\u001b[35m acc:\u001b[94m 47.393939\u001b[35m fscore_macro:\u001b[94m 0.178154\u001b[35m val_loss:\u001b[94m 1.512653\u001b[35m val_acc:\u001b[94m 44.444444\u001b[35m val_fscore_macro:\u001b[94m 0.156269\u001b[0m\n",
      "\u001b[35mEpoch: \u001b[36m11/30 \u001b[35mTrain steps: \u001b[36m155 \u001b[35mVal steps: \u001b[36m34 \u001b[32m0.10s \u001b[35mloss:\u001b[94m 1.472228\u001b[35m acc:\u001b[94m 47.878788\u001b[35m fscore_macro:\u001b[94m 0.184651\u001b[35m val_loss:\u001b[94m 1.631470\u001b[35m val_acc:\u001b[94m 42.749529\u001b[35m val_fscore_macro:\u001b[94m 0.142308\u001b[0m\n",
      "\u001b[35mEpoch: \u001b[36m12/30 \u001b[35mTrain steps: \u001b[36m155 \u001b[35mVal steps: \u001b[36m34 \u001b[32m0.10s \u001b[35mloss:\u001b[94m 1.471659\u001b[35m acc:\u001b[94m 46.787879\u001b[35m fscore_macro:\u001b[94m 0.180527\u001b[35m val_loss:\u001b[94m 1.497583\u001b[35m val_acc:\u001b[94m 48.210923\u001b[35m val_fscore_macro:\u001b[94m 0.183189\u001b[0m\n",
      "Epoch 12: val_acc improved from 46.70433 to 48.21092, saving file to model/minpool_embedding_mlp/checkpoint_epoch_12.ckpt\n",
      "\u001b[35mEpoch: \u001b[36m13/30 \u001b[35mTrain steps: \u001b[36m155 \u001b[35mVal steps: \u001b[36m34 \u001b[32m0.11s \u001b[35mloss:\u001b[94m 1.464107\u001b[35m acc:\u001b[94m 48.080808\u001b[35m fscore_macro:\u001b[94m 0.183899\u001b[35m val_loss:\u001b[94m 1.469841\u001b[35m val_acc:\u001b[94m 47.269303\u001b[35m val_fscore_macro:\u001b[94m 0.190618\u001b[0m\n",
      "\u001b[35mEpoch: \u001b[36m14/30 \u001b[35mTrain steps: \u001b[36m155 \u001b[35mVal steps: \u001b[36m34 \u001b[32m0.09s \u001b[35mloss:\u001b[94m 1.411627\u001b[35m acc:\u001b[94m 49.414141\u001b[35m fscore_macro:\u001b[94m 0.186381\u001b[35m val_loss:\u001b[94m 1.472379\u001b[35m val_acc:\u001b[94m 48.022599\u001b[35m val_fscore_macro:\u001b[94m 0.210356\u001b[0m\n",
      "\u001b[35mEpoch: \u001b[36m15/30 \u001b[35mTrain steps: \u001b[36m155 \u001b[35mVal steps: \u001b[36m34 \u001b[32m0.09s \u001b[35mloss:\u001b[94m 1.409669\u001b[35m acc:\u001b[94m 49.333333\u001b[35m fscore_macro:\u001b[94m 0.200269\u001b[35m val_loss:\u001b[94m 1.478686\u001b[35m val_acc:\u001b[94m 48.022599\u001b[35m val_fscore_macro:\u001b[94m 0.199691\u001b[0m\n",
      "\u001b[35mEpoch: \u001b[36m16/30 \u001b[35mTrain steps: \u001b[36m155 \u001b[35mVal steps: \u001b[36m34 \u001b[32m0.10s \u001b[35mloss:\u001b[94m 1.404388\u001b[35m acc:\u001b[94m 49.979798\u001b[35m fscore_macro:\u001b[94m 0.201918\u001b[35m val_loss:\u001b[94m 1.495662\u001b[35m val_acc:\u001b[94m 48.210923\u001b[35m val_fscore_macro:\u001b[94m 0.191311\u001b[0m\n",
      "\u001b[35mEpoch: \u001b[36m17/30 \u001b[35mTrain steps: \u001b[36m155 \u001b[35mVal steps: \u001b[36m34 \u001b[32m0.10s \u001b[35mloss:\u001b[94m 1.388562\u001b[35m acc:\u001b[94m 50.505051\u001b[35m fscore_macro:\u001b[94m 0.204492\u001b[35m val_loss:\u001b[94m 1.654856\u001b[35m val_acc:\u001b[94m 37.288136\u001b[35m val_fscore_macro:\u001b[94m 0.178082\u001b[0m\n",
      "\u001b[35mEpoch: \u001b[36m18/30 \u001b[35mTrain steps: \u001b[36m155 \u001b[35mVal steps: \u001b[36m34 \u001b[32m0.09s \u001b[35mloss:\u001b[94m 1.408549\u001b[35m acc:\u001b[94m 49.050505\u001b[35m fscore_macro:\u001b[94m 0.204913\u001b[35m val_loss:\u001b[94m 1.450791\u001b[35m val_acc:\u001b[94m 49.905838\u001b[35m val_fscore_macro:\u001b[94m 0.221205\u001b[0m\n",
      "Epoch 18: val_acc improved from 48.21092 to 49.90584, saving file to model/minpool_embedding_mlp/checkpoint_epoch_18.ckpt\n",
      "\u001b[35mEpoch: \u001b[36m19/30 \u001b[35mTrain steps: \u001b[36m155 \u001b[35mVal steps: \u001b[36m34 \u001b[32m0.10s \u001b[35mloss:\u001b[94m 1.389862\u001b[35m acc:\u001b[94m 49.939394\u001b[35m fscore_macro:\u001b[94m 0.209093\u001b[35m val_loss:\u001b[94m 1.480247\u001b[35m val_acc:\u001b[94m 46.892655\u001b[35m val_fscore_macro:\u001b[94m 0.187884\u001b[0m\n",
      "\u001b[35mEpoch: \u001b[36m20/30 \u001b[35mTrain steps: \u001b[36m155 \u001b[35mVal steps: \u001b[36m34 \u001b[32m0.10s \u001b[35mloss:\u001b[94m 1.364159\u001b[35m acc:\u001b[94m 51.474747\u001b[35m fscore_macro:\u001b[94m 0.219885\u001b[35m val_loss:\u001b[94m 1.415635\u001b[35m val_acc:\u001b[94m 49.340866\u001b[35m val_fscore_macro:\u001b[94m 0.220972\u001b[0m\n",
      "\u001b[35mEpoch: \u001b[36m21/30 \u001b[35mTrain steps: \u001b[36m155 \u001b[35mVal steps: \u001b[36m34 \u001b[32m0.09s \u001b[35mloss:\u001b[94m 1.393892\u001b[35m acc:\u001b[94m 49.494949\u001b[35m fscore_macro:\u001b[94m 0.213785\u001b[35m val_loss:\u001b[94m 1.487176\u001b[35m val_acc:\u001b[94m 47.645951\u001b[35m val_fscore_macro:\u001b[94m 0.207495\u001b[0m\n",
      "\u001b[35mEpoch: \u001b[36m22/30 \u001b[35mTrain steps: \u001b[36m155 \u001b[35mVal steps: \u001b[36m34 \u001b[32m0.10s \u001b[35mloss:\u001b[94m 1.346546\u001b[35m acc:\u001b[94m 51.151515\u001b[35m fscore_macro:\u001b[94m 0.219418\u001b[35m val_loss:\u001b[94m 1.473852\u001b[35m val_acc:\u001b[94m 47.457627\u001b[35m val_fscore_macro:\u001b[94m 0.231198\u001b[0m\n",
      "\u001b[35mEpoch: \u001b[36m23/30 \u001b[35mTrain steps: \u001b[36m155 \u001b[35mVal steps: \u001b[36m34 \u001b[32m0.12s \u001b[35mloss:\u001b[94m 1.349921\u001b[35m acc:\u001b[94m 51.434343\u001b[35m fscore_macro:\u001b[94m 0.229022\u001b[35m val_loss:\u001b[94m 1.406151\u001b[35m val_acc:\u001b[94m 50.847458\u001b[35m val_fscore_macro:\u001b[94m 0.220293\u001b[0m\n",
      "Epoch 23: val_acc improved from 49.90584 to 50.84746, saving file to model/minpool_embedding_mlp/checkpoint_epoch_23.ckpt\n",
      "\u001b[35mEpoch: \u001b[36m24/30 \u001b[35mTrain steps: \u001b[36m155 \u001b[35mVal steps: \u001b[36m34 \u001b[32m0.10s \u001b[35mloss:\u001b[94m 1.349590\u001b[35m acc:\u001b[94m 52.040404\u001b[35m fscore_macro:\u001b[94m 0.234871\u001b[35m val_loss:\u001b[94m 1.409325\u001b[35m val_acc:\u001b[94m 50.282486\u001b[35m val_fscore_macro:\u001b[94m 0.237596\u001b[0m\n",
      "\u001b[35mEpoch: \u001b[36m25/30 \u001b[35mTrain steps: \u001b[36m155 \u001b[35mVal steps: \u001b[36m34 \u001b[32m0.10s \u001b[35mloss:\u001b[94m 1.357233\u001b[35m acc:\u001b[94m 51.111111\u001b[35m fscore_macro:\u001b[94m 0.232781\u001b[35m val_loss:\u001b[94m 1.425496\u001b[35m val_acc:\u001b[94m 49.905838\u001b[35m val_fscore_macro:\u001b[94m 0.198345\u001b[0m\n",
      "\u001b[35mEpoch: \u001b[36m26/30 \u001b[35mTrain steps: \u001b[36m155 \u001b[35mVal steps: \u001b[36m34 \u001b[32m0.10s \u001b[35mloss:\u001b[94m 1.344421\u001b[35m acc:\u001b[94m 52.080808\u001b[35m fscore_macro:\u001b[94m 0.237099\u001b[35m val_loss:\u001b[94m 1.636085\u001b[35m val_acc:\u001b[94m 41.242938\u001b[35m val_fscore_macro:\u001b[94m 0.234494\u001b[0m\n",
      "\u001b[35mEpoch: \u001b[36m27/30 \u001b[35mTrain steps: \u001b[36m155 \u001b[35mVal steps: \u001b[36m34 \u001b[32m0.10s \u001b[35mloss:\u001b[94m 1.355992\u001b[35m acc:\u001b[94m 51.151515\u001b[35m fscore_macro:\u001b[94m 0.228557\u001b[35m val_loss:\u001b[94m 1.418030\u001b[35m val_acc:\u001b[94m 51.035782\u001b[35m val_fscore_macro:\u001b[94m 0.229967\u001b[0m\n",
      "Epoch 27: val_acc improved from 50.84746 to 51.03578, saving file to model/minpool_embedding_mlp/checkpoint_epoch_27.ckpt\n",
      "\u001b[35mEpoch: \u001b[36m28/30 \u001b[35mTrain steps: \u001b[36m155 \u001b[35mVal steps: \u001b[36m34 \u001b[32m0.10s \u001b[35mloss:\u001b[94m 1.327232\u001b[35m acc:\u001b[94m 52.767677\u001b[35m fscore_macro:\u001b[94m 0.245662\u001b[35m val_loss:\u001b[94m 1.436181\u001b[35m val_acc:\u001b[94m 48.022599\u001b[35m val_fscore_macro:\u001b[94m 0.224116\u001b[0m\n",
      "\u001b[35mEpoch: \u001b[36m29/30 \u001b[35mTrain steps: \u001b[36m155 \u001b[35mVal steps: \u001b[36m34 \u001b[32m0.10s \u001b[35mloss:\u001b[94m 1.327346\u001b[35m acc:\u001b[94m 51.717172\u001b[35m fscore_macro:\u001b[94m 0.236932\u001b[35m val_loss:\u001b[94m 1.396125\u001b[35m val_acc:\u001b[94m 51.035782\u001b[35m val_fscore_macro:\u001b[94m 0.227870\u001b[0m\n",
      "\u001b[35mEpoch: \u001b[36m30/30 \u001b[35mTrain steps: \u001b[36m155 \u001b[35mVal steps: \u001b[36m34 \u001b[32m0.10s \u001b[35mloss:\u001b[94m 1.310088\u001b[35m acc:\u001b[94m 53.252525\u001b[35m fscore_macro:\u001b[94m 0.252968\u001b[35m val_loss:\u001b[94m 1.425799\u001b[35m val_acc:\u001b[94m 48.210923\u001b[35m val_fscore_macro:\u001b[94m 0.232581\u001b[0m\n",
      "Restoring data from model/minpool_embedding_mlp/checkpoint_epoch_27.ckpt\n"
     ]
    }
   ],
   "source": [
    "models, loggings, experiments, test_dataloaders = train(hidden_size=hidden_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Évaluation et analyse de résultats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(experiments = experiments):\n",
    "    for key in aggregations.keys():\n",
    "        print(\"Test for :\", key, \"\\n\")\n",
    "        experiments[key].test(test_dataloaders[key])\n",
    "        print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test for : average \n",
      "\n",
      "Found best checkpoint at epoch: 30\n",
      "lr: 0.001, loss: 0.632674, acc: 77.8586, fscore_macro: 0.758985, val_loss: 0.946139, val_acc: 70.8098, val_fscore_macro: 0.675723\n",
      "Loading checkpoint model/average_embedding_mlp/checkpoint_epoch_30.ckpt\n",
      "Running test\n",
      "\u001b[35mTest steps: \u001b[36m34 \u001b[32m0.02s \u001b[35mtest_loss:\u001b[94m 0.946139\u001b[35m test_acc:\u001b[94m 70.809793\u001b[35m test_fscore_macro:\u001b[94m 0.675723\u001b[0m          \n",
      "\n",
      "\n",
      "Test for : maxpool \n",
      "\n",
      "Found best checkpoint at epoch: 30\n",
      "lr: 0.001, loss: 1.43109, acc: 48.9293, fscore_macro: 0.278957, val_loss: 1.52163, val_acc: 45.1977, val_fscore_macro: 0.182609\n",
      "Loading checkpoint model/maxpool_embedding_mlp/checkpoint_epoch_30.ckpt\n",
      "Running test\n",
      "\u001b[35mTest steps: \u001b[36m34 \u001b[32m0.01s \u001b[35mtest_loss:\u001b[94m 1.521630\u001b[35m test_acc:\u001b[94m 45.197740\u001b[35m test_fscore_macro:\u001b[94m 0.182609\u001b[0m          \n",
      "\n",
      "\n",
      "Test for : minpool \n",
      "\n",
      "Found best checkpoint at epoch: 27\n",
      "lr: 0.001, loss: 1.35599, acc: 51.1515, fscore_macro: 0.228557, val_loss: 1.41803, val_acc: 51.0358, val_fscore_macro: 0.229967\n",
      "Loading checkpoint model/minpool_embedding_mlp/checkpoint_epoch_27.ckpt\n",
      "Running test\n",
      "\u001b[35mTest steps: \u001b[36m34 \u001b[32m0.01s \u001b[35mtest_loss:\u001b[94m 1.418030\u001b[35m test_acc:\u001b[94m 51.035782\u001b[35m test_fscore_macro:\u001b[94m 0.229967\u001b[0m          \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyse des resultats ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut déduire que le modèle utilisant l'agrégation moyenne (Average Embedding) a nettement surpassé les modèles Maxpool et Minpool en termes de perte, de précision et de F-score. Cela suggère que l'approche d'agrégation moyenne est plus efficace pour ce problème spécifique, offrant un meilleur équilibre entre la capacité de modélisation et la généralisation par rapport aux approches Maxpool et Minpool."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il est a noter que pour l'experience nous avons garde une taille de la couche cachee identique (100) sur chacune des approches pour quon puisse avoir une comparaison sur la meme base."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
